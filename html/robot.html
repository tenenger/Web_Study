<!--
인터넷상에는 사람이 아닌 소프트웨어가 페이지를 접속하는데
접속할 수 있는 허용을 조절하는 txt를 확인하는 방법은 해당 주소 뒤에 robots.txt를 적으면 알 수 있다.

user-agent:*
disallow: /
sitemap:/sitemap

대략 위의 내용을 확인 할 수 있는데
user-agent는 해당 사용자(로봇)이 접근하는 브라우저를 설정하는것으로 *은 아무거나 다된다는 뜻이다.
disallow는 해당 사용자가 접근을 허용하지 않는것이며, /는 모든 페이지를 거부한다는 뜻이다.
sitemap은 해당 페이지의 모든 주소를 알려주는 지도같은 역할이다.
-->
